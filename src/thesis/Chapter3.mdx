import {Suspense} from 'react';

# Using Graphs of Convex Sets to Guide Nonconvex Trajectory Optimization

## 3.1    High-Level Approach

The Graph of Convex Sets (GCS) framework [@marcucci2024shortest]
provides a powerful tool for addressing mixed discrete and continuous
decision making problems whose discrete component can be transcribed
into a network flow problem like shortest path. The framework provides a
transcription from a graph of convex sets into a mixed-integer
optimization, but also provides a tight convex relaxation so that many
of these generalized network flow problems can be solved to global
optimality by only solving the convex relaxation and employing a simple
rounding strategy. The term "rounding\" is commonly used because the
convex relaxation of the mixed-integer problem may produce floating
point values which are (hopefully) close to, but not exactly, zero or
one; the rounding step takes the approximate solutions and "rounds\"
them to nearby solutions that completely satisfy the original
constraints.

@marcucci2023motion provides a transcription of the collision-free
motion planning problem into a GCS problem which provides new
capabilities for global trajectory optimization of smooth trajectories,
avoiding the local minima that are normally inherent in collision-free
trajectory optimization. This work demonstrated the power of efficient
convex optimization in solving seemingly nonconvex robotics problems,
and encourages us to continue working on tight convex relaxations
[@graesdal2024towards] for increasingly complex problems. However, the
strict reliance on convexity may not be necessary. Many costs and
constraints that are used in trajectory optimization contain
nonlinearities for which we don't yet have efficient relaxations; some
of these nonconvexities are benign (do not introduce new local minima).

In GCS, we form a graph in which we associate convex sets $X_v$ with
vertices $v \in V$, and associate convex sets
$(x_u, x_v) \in \mathcal X_e$ with directed edges
$e = (u,v) \in \mathcal E$. The shortest path problem on a GCS can be
formulated as the search for a path $p \in \relax$ (defined as an
ordered list of vertices and edges) where:
<div className="mt-3">
$$
\begin{align}
\text{minimize}\quad & \sum_{e=(u,v) \in \mathcal E_p} l_e(x_u, x_v) \\ 
\text{subject to}\quad & p \in \relax, \\
& x_v \in \mathcal X_v, & \forall v \in p, \\
& (x_u, x_v) \in \mathcal X_e, & \forall e=(u,v) \in \mathcal E_p.
\end{align}
$$
</div>

$l_e$ are convex costs associated with each edge $e$. Here
we wish to extend the framework to allow $\mathcal X_v$ and
$\mathcal X_e$ to be support nonconvex sets (described via the union of
nonconvex constraints), and $l_e$ to include nonconvex costs. The
fundamental question we explore here is: how can we effectively use GCS
to guide nonlinear optimization, to capture the global optimization
benefits of GCS (which combat local minima) but still solve the
nonconvex problem?

Broadly speaking, when faced with a nonlinear objective or constraint,
then we have two options: We can explore a convex surrogate (which can
be either a relaxation/outer approximation, or simply a convex
approximation), or we can attempt to deal with the nonlinearities
directly with nonlinear optimization algorithms. We propose a hybrid
approach:

**Convex Surrogates as a Guide:** We aim to find the tight convex
relaxations or close convex approximations for smooth nonlinear
constraints and objectives. These approximations are incorporated into
the GCS problem. The convex relaxation of GCS is then used to
effectively guide the subsequent rounding process. Importantly, stronger
convex approximations yield stronger guidance, increasing solution
quality.

**Rounding with Nonlinear Optimization:** Nonlinear optimization fills
the gaps left by the convex relaxations. During rounding, we directly
address the original nonlinearities using appropriate algorithms.
Warm-starting the nonlinear solver with the solution to the convex
approximation allows this step to further refine the solution.

There are some important aspects of the GCS formulation which can make
this approach very powerful. The solution to the GCS convex relaxation,
even when the relaxation is not tight and edges are assigned values
between zero and one, can be interpreted as a probability distribution
on the flow polytope. The natural rounding scheme introduced in
@marcucci2023motion used this "edge probability\" interpretation. In
this work, we further leverage this probabilistic interpretation -- GCS
doesn't just tell us a single path through the graph, it gives us a
probability distribution over paths which effectively guides our global
search through many path-homotopies and navigates multiple local minima
of the original nonlinear program.

In some problems, one may be able to restrict the nonconvexity to only
appear in the objective, $l_e$. In this important class of problems,
through appropriate care in choosing the solver, it may be possible to
use the convex formulation to guarantee completeness of the planner.
However we do not explore this approach here, as many important
nonconvexities we wish to study are more naturally represented as
constraints. Instead, like other nonlinear trajectory optimization
formulations, we sacrifice guarantees and instead focus here on the
empirical performance of the algorithm in representative problem
instances.

## 3.2    Nonlinear extension to GCS Trajectory Optimization

We formulate the trajectory optimization problem as the optimization
over continuous curves over a graph of convex sets, closely following
the formulation in [@marcucci2023motion], but with additional nonconvex
costs and constraints added to the vertices and edges. In particular, we
associate with each vertex a Bézier curve describing the configuration
space path, $r(s),$ defined over the interval $s \in [0, 1]$, and a
scalar time duration, $h.$ The final parameterized trajectory is
$q(t) = r(t/h).$ Note that [@marcucci2023motion] used a richer
parameterization for the time re-scaling, but this was primarily
introduced to provide high-order derivative continuity constraints which
we will handle more directly in this work.

The Bézier curve parameterization over convex sets in configuration
space allows us to impose convex constraints which *guarantee* that the
Bézier curves in the solution path stay inside the convex collision-free
configuration-space regions *for all time* (not just at the sample
points) -- providing strong certificates that the motions are collision
free. This is accomplished by constraining the control points of the
path $r(s)$, which we denote with decision variables $r_i$, to be inside
the convex sets, and leveraging the convex hull property of Bézier
curves. The original formulation also provides convex constraints which
can guarantee that the path was smooth and that velocity limits are
strictly imposed for all $t.$ One of the first places where the
transcription in [@marcucci2023motion] was limited was that it did not
provide a similar set of convex constraints to enforce higher-degree
derivative constraints (e.g. on acceleration and jerk).

In the remainder of this section, we describe how we address these
derivative continuity and other constraints directly with convex
surrogates at the level of GCS and nonconvex optimization in the
rounding stage.

### 3.2.1    Minimizing path duration, length, and smoothness

The transcription in @marcucci2023motion introduced *convex* objective
functions which directly optimize a weighted sum of the total path
duration, and convex surrogates for path length and a path velocity
regularization. We use the same objectives here, and add additional
support for penalizing the higher derivatives of the trajectory:
<div className="mt-3">
$$
\text{minimize}\quad aT + b L(r) + \sum_{n=2}^N c_n D(r,h,n)
$$
</div>
Here $a$, $b$, and $c_n$ are user-specified
positive scalar weights. These weights represent the importance given to
the trajectory duration, $T,$ path length, $L(r),$ and regularization of
the nth order derivative $D(r,h, n),$ respectively.

Minimizing trajectory duration is achieved by considering the convex
cost associated with minimizing each individual segment's duration's
($h_i$):
<div className="mt-3">
$$
T = \sum_{i \in \mathcal I} h_i.
$$
</div>

To minimize path length, we minimize the cumulative length between
control points of each Bézier curve ($r_i$):
<div className="mt-3">
$$
L(r_i) = \sum_{k=0}^{d-1} |r_{i,k+1} - r_{i,k} |_2.
$$
</div>
This provides an upper bound on path
length and avoids unnecessary numerical integration while maintaining
convexity.

Finally, to promote smoothness, we can minimize the trajectory's
higher-order derivatives. We achieve this by minimizing the squared
distance between control points of the Nth minus one derivative of
$r(s)$, normalized by the duration:
<div className="mt-3">
$$
D (r,h,n) = \frac{1}{h} \sum_{k=0}^{d-n} \left| \frac{d^{n-1}r_{i,k+1}}{ds^{n-1}} - \frac{d^{n-1}r_{i,k}}{ds^{n-1}}\right|_2^2.
$$
</div>
This expression remains convex for
$h > 0$. This is an approximation for regularizing the true time
derivative, $\frac{d^nq(t)}{dt^n}$, which involves a term of $h^{n}$ in
the denominator. While this true nonconvex cost could be directly
enforced during the rounding stage, we have found the convex surrogate
to be sufficiently tight in practice, especially for higher-order
derivatives where the $h^{2(n-1)}$ denominator can lead to numerical
challenges. Therefore, we use the convex surrogate for both the
relaxation and the rounding.

By combining these sub-objectives, we can concurrently optimize for
trajectory duration
[\[eq:time_cost\]](#eq:time_cost), path length
[\[eq:path_length_cost\]](#eq:path_length_cost), and smoothness
[\[eq:path_derivative_cost\]](#eq:path_derivative_cost), tailoring the optimization to
specific task requirements.

### 3.2.2    Derivative Constraints

Many robot controllers require that trajectories strictly adhere to
velocity, acceleration, and even jerk limits. In some cases,
acceleration limits can also be used as a surrogate for torque limits.

For velocity constraints, we leverage the fact that the derivative of a
Bézier curve is also a Bézier curve. This allows us to impose linear
constraints on the control points of the path, guaranteeing that
velocity limits are respected throughout the entire trajectory. Here
$\mathcal V$ is a convex set of the allowable velocities.
<div className="mt-3">
$$
\dot r(s) \in h \mathcal V.
$$
</div>

However, constraints on higher-order derivatives, such as
acceleration, are inherently nonlinear due to the relationship between
path derivatives and time scaling:
<div className="mt-3">
$$
\frac{d^N q(t)}{dt^N} = \frac{d^N r(s)/ds^N}{h^N}.
$$
</div>

<figure id="fig:mcCormick" className="flex flex-col items-center">
    <Suspense fallback={null}>
        <img className="w-72" src="figures/math/mcCormickEnvelope.png" />
    </Suspense>
    <figcaption>
        Figure 1: Convex Approximations of 1D acceleration limits. The filled
        gray area represents the feasible set of the nonlinear constraint. The
        blue line represents a McCormick envelope, a convex relaxation of the
        original constraint. The red lines illustrate a tighter piecewise
        envelope. The orange line shows a simpler approximation.
    </figcaption>
</figure>

For example, consider a 1D path with acceleration $x$ and limits \[-1,
1\]. The nonlinear constraint is:
<div className="mt-3">
$$
-1 \leq \frac{x}{h^2} \leq 1.
$$
</div>
The feasible set is highlighted in gray in Figure [3.1](#fig:mcCormick)

The McCormick envelope for this constraint, considering the range of $h$
between $h_{min}$ and $h_{max}$, can be constructed using the following
inequalities:
<div className="mt-3">
$$
h^N \leq \frac{h_{max}^N - h_{min}^N}{h_{max} - h_{min}}h + \frac{h_{max}h_{min}^N - h_{min}h_{max}^N}{h_{max} - h_{min}}.
$$
</div>
The single McCormick envelope using
[\[eq:mcCormick_bound\]](#eq:mcCormick_bound) is shown as a blue line. Alternatively,
we could choose to copy a configuration space region into e.g. separate
slow, normal, and fast regions, shown in red. We can use the discrete
machinery in GCS to enable these tighter piecewise-McCormick envelopes,
but at the cost of increasing the size of the graph and the solve times.

Alternatively, we use a simpler linear approximation, where $\mathcal D$
is a convex set with the allowable derivatives:
<div className="mt-3">
$$
\frac{d^N r(s)}{ds^N} \in h_0^{N-1} h \mathcal D,
$$
</div>
where $h_0$ is a
characteristic time constant. While this approximation is less tight
than the piecewise-McCormick envelope and too conservative for large
accelerations, it is often sufficient for guiding the optimization and
can be computationally more efficient.

Regardless of the chosen approximation, we refine the solution during
the rounding stage using nonlinear optimization to ensure that the final
trajectory strictly satisfies the original nonlinear acceleration
constraints:
<div className="mt-3">
$$
\frac{d^Nr(s)}{ds^N} \in h^N \mathcal D.
$$
</div>

### 3.2.3    Continuity

In GCS trajectory optimization we use equality constraints on the path
and its derivatives to smoothly stitch together trajectory segments from
individual regions. The initial and terminal points of the scaled
trajectory $q_i$ correspond to the first and last control points of
Bézier curve: $r_{i,0} = r_i(0)$ and $r_{i+1,d} = r_{i+1}(S)$.

Zero-order continuity (position continuity) is achieved by requiring the
initial and terminal points of consecutive Bézier curves to be equal:
<div className="mt-3">
$$
r_{k,d} = r_{k+1,0}.
$$
</div>
This guarantees that the robot's path
is continuous without any teleportation.

To avoid sudden changes in velocity and acceleration, we can enforce
higher-order continuity. The rounding problem receives these nonconvex
equality constraint that relate the derivatives of consecutive Bézier
curves:
<div className="mt-3">
$$
\frac{d^Nr_{k,d}}{ds^N}h_{k+1}^N = \frac{d^Nr_{k+1,0}}{ds^N}h_k^N.
$$
</div>
We introduce a convex surrogate by replacing the time scaling variables
with a constant value ($h_0$) for each region:
<div className="mt-3">
$$
\frac{d^Nr_{k,d}}{ds^N}h_{0, k+1}^N = \frac{d^Nr_{k+1,0}}{ds^N}h_{0,k}^N.
$$
</div>
In practice, we typically set $h_0$ to one, effectively enforcing
continuity on the path variable $r(s)$. However, depending on the
specific problem and prior knowledge about set sizes and velocity
bounds, a different constant value might be more suitable.

### 3.2.4    Collision Avoidance

For static obstacles, we leverage the convex hull property of Bézier
curves. We assign a collision-free set ($\mathcal Q_i$) to each vertex
in the GCS graph and constrain the control points of the corresponding
trajectory segment ($r_i$) to lie within this set. This guarantees that
the entire segment remains collision-free. These sets can represent both
the robot's self-collision-free space and the space around static
obstacles, which can be efficiently generated using tools like
IRIS-NP [@petersen2023growing]. This approach leverages the
combinatorial power of the GCS framework to efficiently determine the
optimal path around obstacles. It is particularly beneficial for robots
with complex morphology (e.g., bimanual or legged robots) or known
cluttered environments. For pick- and place task, we recommend
generating a library of swappable regions that treat grasped objects as
welded geometries.

In dynamic environments, pre-computing collision-free sets for all
possible scenarios is impractical. Instead, we utilize minimum distance
constraints during the rounding stage. Let $R_k(r(s_i))$ represent the
geometry of the $k$-th link of the robot at sample point $s_i$, and
$O_j$ represent the geometry of the $j$-th object in the environment. We
enforce the following constraint:
<div className="mt-3">
$$
\min_{x \in R_k(r(s_i)), y \in O_j} | x - y |_2 \geq d_{\text{min}}, \hspace{25pt} \forall (j, k) \in \mathcal{C}, \forall s_i \in S_I,
$$
</div>
where $\mathcal{C}$ represents the set of all collision pairs between
robot links and environment objects.

We do not currently introduce any convex surrogate for these
constraints; they are only introduced in the rounding. These
constraints, while nonconvex, enforce local obstacle avoidance in the
rounding stage and allow the robot to react to unexpected changes in the
environment. Importantly, the GCS relaxation guides a global search
through many path-homotopies and navigates multiple local minima,
reducing the likelihood of becoming 'stuck', a common issue with
traditional trajectory optimization.

Although we cannot easily enforce that these constraints are satisfied
for the entire trajectory, we enforce them at a finite set of subsamples
in each region. To choose the number of subsamples, we provide a tunable
step size and use a simple heuristic (Algorithm
[\[alg:max_dist_polyhedra\]](#alg:max_dist_polyhedra)}) to estimate the length of each
convex region. This heuristic samples a random linear cost from a
Gaussian distribution and uses it to find the points within the
polyhedron that are farthest apart in the direction of the cost. By
repeating this process for N samples and taking the maximum distance
found, we obtain an estimate of the region's length, which guides the
selection of subsamples given a step size.

:::: algorithm
::: algorithmic
$dist_{max} \gets 0$

Sample a random vector $c \sim \mathcal{N}(0, I)$ Solve the optimization
problem: $$\begin{aligned}
    \min_{x_1, x_2} \quad & c^T(x_1 - x_2) \\
    \text{subject to} \quad & Ax_1 \leq b, \\
    & Ax_2 \leq b
\end{aligned}$$ $dist_{max} \gets max(dist_{max}, |x_1^* - x_2^*|_2)$
$dist_{max}$
:::
::::

### 3.2.5    Task Space Constraints

In robotic manipulation, we often need to couple task-space goals (e.g.
grasp-poses or end-effector velocity limits) with our joint space costs
and constraints. We can enforce constraints on the robot's end-effector
position, gaze direction, center of mass, or any other relevant function
at user-specified points $s_i \in S_U$ along the trajectory $r(s_i)$:
<div className="mt-3">
$$
f_{kin}(r(s_i)) \in \relax, \hspace{35pt} \forall s_i \in S_U.
$$
</div>
For common manipulators the
forward kinematics $f_{kin}(r(s_i))$ are typically nonconvex, thus
handled in the rounding stage. We leverage Drake's rich library of
kinematic costs and constraints to write the minimal set of constraints
required by the task (e.g. we don't constrain the entire pose of the
hand if you only need the fingers to be at the grasp point). The convex
decomposition of the configuration space used in GCS also aids the
satisfaction of these potentially nonconvex kinematic constraints.

While we address the nonconvexity of task-space position constraints
during the rounding stage, it can be beneficial to introduce convex
surrogates in the GCS relaxation to guide the optimization toward
feasible solutions.

One approach is to solve the inverse kinematics problem a priori for the
desired task-space position constraints, targeting a specific point,
$s_i$, along the trajectory segment represented by the vertex. We can
use the Chebyshev center of a vertex in the relevant subgraph as an
initial guess for the inverse kinematics solver. If a solution is found,
this joint configuration can serve as a simple convex surrogate in the
relaxation, effectively representing a point constraint at $s_i$ within
the original convex region.

Alternatively, we can leverage the IRIS-NP
algorithm [@petersen2023growing] to generate a convex inner
approximation of the set of feasible task-space position constraints
within the original convex region. Specifically, we can use IRIS-NP to
grow a convex region within the original region, subject to the
task-space position constraint. This results in a new convex region in
joint space that corresponds to task-space positions satisfying the
constraint, allowing us to impose a linear constraint on the
corresponding vertex in the GCS relaxation.

When handling delicate objects or executing challenging maneuvers, task
space velocity and accelerations constraints come in handy. For example,
when placing a tall box on a table, bounding task-space velocities can
prevent the box from tipping over while not explicitly restriction
configuration space velocities. Task-space velocity and acceleration
constraints can be expressed using the kinematic Jacobian ($J$) and its
derivative:
<div className="mt-3">
$$
\begin{align}
J(r(s_i)) \dot{r}(s_i) &\in h\mathcal V, &&\forall s_i \in S_U,\\
J(r(s_i)) \ddot{r}(s_i) + h\dot{J}(r(s_i)) \dot{r}(s_i) &\in h^2\mathcal A, &&\forall s_i \in S_U.
\end{align}
$$
</div>
where $\mathcal V, \mathcal A\subseteq \mathbb R^6$ are
bounded convex sets constraining the spatial velocities and
accelerations, respectively. Exploring convex surrogates for these
constraints is more challenging due to their nonlinear dependence on the
Jacobian and its derivative. One potential approach is to extend the
IRIS-NP algorithm to generate regions that encompass not only
configurations but also trajectory segments, allowing us to impose
velocity constraints on the control points of the Bézier curves.

## 3.3    Multimodal Planning with Hierarchical Graph Structures

The Graph of Convex Sets framework can be leveraged to incorporate
discrete decision making. A task, that can be transcribed to desired
positions/velocities/accelerations in configuration or task space can be
tackled through hierarchical graph structures, where multiple subgraphs
represent different task phases and allow for simultaneous optimization
of discrete choices and continuous trajectories.

### 3.3.1    Subgraphs and Subspaces

Within this structure, a *subgraph* represents a connected set of
collision-free regions in configuration space, corresponding to various
task stages such as grasping, manipulation, or navigation. Individual
configurations like start and goal poses are represented as singletons
within their respective subgraphs.

Each subgraph offers control over the objective and constraints with
respect to the associated task stage. The weights of the objectives can
be adjusted, allowing some subgraphs to favor minimum-time planning over
the path length cost or to optimize for stronger smoothness. To traverse
slower through a subgraph, the velocity and derivative bounds in
configuration or task space can be further tightened. Further, the
minimum duration bounds can be adjusted to introduce delays which would
give a gripper enough time to close before continuing with the remaining
plan.

Directed edges connect these subgraphs, enabling transitions between
task stages. *Subspaces* act as optional position constraints on these
directed edges, where the control point connecting the subgraphs must
also lie within the subspace. It does not introduce new vertices. A
subspace is a convex set, in the simplest case just a point constraint.
Additional constraints like tighter, or zero, derivative bounds can be
constraint on the edges which can be useful to decelerate at an
intermediate waypoint.

### 3.3.2    Sequential and Parallel Subgraphs

<figure id="fig:sequential_graph">
<Suspense fallback={null}>
<img src="figures/math/sequential_graph.png"/>
</Suspense>
<figcaption>Figure 2: Sequential and parallel subgraphs in a hierarchical graph
structure. Blue shapes represent subgraphs ($G_S$, $G_T$, $G_{1-4}$),
and red denote subspace ($S_{1-2}$) constraints on gray edges connecting
the subgraphs.</figcaption>
</figure>

Arranging subgraphs sequentially and in parallel empowers the
hierarchical structure to handle both sequential task execution and
decision-making between alternatives. Sequential subgraphs enable
planning with intermediate goals, optimizing for smooth transitions by
ensuring continuity on all continuous variables. Parallel subgraphs
allow selecting one path among several, choosing the option that
minimizes the objective function while adhering to all constraints.

We will use figure [3.2](#fig:sequential_graph) to illustrate the potential of
sequential and parallel graphs, where $G_S$, $G_{1-4}$, and $G_T$
represent the subgraphs (in blue) and $S_1$, $S_2$ the subspaces (in
red). Here $G_S$, $G_T$ represent the start and goal configurations
respectively, which are singletons sets in a subgraph with no more other
regions connected to. $G_{1-4}$ on the other hand contain multiple sets,
which in the motion planning setting are connected based weather a pair
of regions intersects. $S_1$. There are two different sequences of
graphs one can traverse to to get from the start to the target. The
first option is through:
$G_S \rightarrow G_1 \rightarrow S_1 \rightarrow  G_2 \rightarrow  G_4 \rightarrow  G_T$,
which goes through the subspace $S_1$ and the subgraph $G_2$.
Alternatively passing with subspace $S_2$ and the subgraph $G_3$ would
result in:
$G_S \rightarrow  G_1 \rightarrow S_2 \rightarrow  G_3 \rightarrow  G_4 \rightarrow G_T$.

Consider a robotic arm tasked with picking up an item (apple or bag of
flour) from a conveyor belt, scanning its Barcode, and dropping it in a
bag. A hierarchical graph structure effectively represents this task:

-   **Start and goal subgraphs ($G_S$, $G_T$):** Singletons representing
    the initial and final configurations of the manipulator. Where the
    final configuration is positioned s.t. it would drop the picked item
    in the bag.

-   **Manipulation subgraphs ($G_1$, $G_4$):** Representing the
    collision-free configuration space of the manipulator and static
    elements of the environment.

-   **Grasp subspaces ($S_1$, $S_2$):** The subspaces could be
    constructed such that $S_1$ contains all possible grasp
    configurations for the apple and $S_2$ all configurations for the
    bag of flour. The velocity and accelerations on the subspace edges
    would be set to zero since the objects are initially at rest.

-   **Barcode scanning subgraphs ($G_2$, $G_3$):** Contains
    configurations s.t. the end-effector with the grasped items would
    pass through the Barcode scanner in task-space. Since the scanner
    may be slow, constraining lower velocity limits on the subgraphs may
    be suitable.

This formulation allows the planner to find a collision-free trajectory
that minimizes a desired objective function (e.g., time or path length),
selects the appropriate object to grasp, and satisfies all task
constraints to scan the Barcodes and drop the item into the bag.

### 3.3.3    Utilizing Subgraphs as Start and Goal Regions

<figure id="fig:multi_start_graph">
<Suspense fallback={null}>
    <img src="figures/math/multi_start_graph.png"/>
</Suspense>
<figcaption>Figure 3: Hierarchical graph structure with subgraphs as start and
goal regions. Blue shapes represent subgraphs ($G_S$, $G_T$, $G_1$),
gray edges connect the subgraphs, and the dummy vertices (orange lines)
enable the selection of any vertex within a subgraph as the effective
start or
target.</figcaption>
</figure>

Hierarchical graph structures offer further flexibility by accommodating
scenarios where the start or goal configurations are not singular points
but rather sets of possibilities. This allows the planner to adapt to
situations with uncertainty or multiple feasible solutions.

Figure [3.3](#fig:multi_start_graph) illustrates such a scenario, where
the start subgraph ($G_S$) encompasses two potential starting
configurations ($G_{S1}$ and $G_{S2}$), while the goal subgraph ($G_T$)
consists of a goal set ($G_{T1}$) and a specific configuration
($G_{T2}$). These start and goal subgraphs are connected by an
intermediate subgraph ($G_1$) composed of multiple regions and edges.

The Shortest Path Problem (SPP) formulation, fundamental to the GCS
framework, requires a single designated start and goal vertex. To
accommodate multiple start or goal regions within a subgraph, we employ
a simple technique: introducing a dummy vertex. This dummy vertex is an
empty set connected to all vertices within the subgraph via directed
edges. This allows the planner to choose any vertex within the subgraph
as the effective start or goal, depending on which path minimizes the
overall objective function. While it would be possible to introduce a
dummy vertex without the subgraph abstraction, using subgraphs provides
a more structured representation. This allows us to impose specific
constraints on only the start and target regions, such as enforcing zero
velocity on all outgoing edges of the start subgraph and on all incoming
edges of the target subgraph.
